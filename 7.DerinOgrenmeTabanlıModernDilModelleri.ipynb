{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b988fcc",
   "metadata": {},
   "source": [
    "### 7.1 Word Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ea8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - WE , kelimeleri sayisal vektörlerle ifade eden bir yöntemdir. \n",
    "# - Bu temsiller, kelimeler arasındaki anlamsal ilişkileri öğrenmeyi saglar.\n",
    "# - Aynı anlamda veya benzer anlamda kullanılan kelimeler vektor uzayında birbirine yakın olur.\n",
    "\n",
    "# CBOW = baglam kelimelere bakrak kelime tahmin etme\n",
    "# Skip-gram = CBOW tersine çalısıyor yani kelimeye bkılarak baglam kelimeleri tahmin ediyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce3a2c",
   "metadata": {},
   "source": [
    "### 7.2 RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cf59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Zaman serisi verisi \n",
    "# - Sekans Verisi ( Sıralı Veri )\n",
    "\n",
    "# Rnn' nin özellikleri \n",
    "    # - Zaman Boyutunda tekrar \n",
    "    # Sekans Verisi için uygun\n",
    "\n",
    "# RNN ile yapılan uygulamalar; \n",
    "#     - Dil Modelleme \n",
    "#     - Konuşma Tanıma\n",
    "#     - Makine Çevirisi\n",
    "#     - Görüntü Tanıma    \n",
    "#     - Metin üretimi\n",
    "#     -Duygu analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f0a0e",
   "metadata": {},
   "source": [
    "#### 7.3 RNN 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea89206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solve Classification problem (Sentiment Analysis in NLP) with RNN (Deep Learning based Language Model)\n",
    "\n",
    "duygu analizi -> bir cumlenin etiketlenmesi (positive ve negative)\n",
    "restaurant yorumlari degerlendirme\n",
    "\"\"\"\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec # metin temsili\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# dataset\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Yemekler harikaydı, her şey taze ve lezzetliydi.\",\n",
    "        \"Garson çok ilgisizdi, siparişimi unuttular.\",\n",
    "        \"Tatlılar gerçekten çok güzeldi, bayıldım!\",\n",
    "        \"Yemekler soğuktu ve tadı hiç hoş değildi.\",\n",
    "        \"Atmosfer oldukça keyifliydi, tekrar geleceğim.\",\n",
    "        \"Fiyatlar biraz yüksekti ama yemekler güzeldi.\",\n",
    "        \"Servis kalitesi çok iyiydi, teşekkürler.\",\n",
    "        \"Yemek çok geç geldi, sabrım kalmadı.\",\n",
    "        \"Lezzetli bir akşam yemeği deneyimledik.\",\n",
    "        \"Bu restoranı asla tavsiye etmem, kötüydü.\",\n",
    "        \"Mekan çok hoştu, özellikle dekorasyonu.\",\n",
    "        \"Yemekler beklediğimden çok daha kötüydü.\",\n",
    "        \"Güzel bir akşam geçirdik, teşekkürler.\",\n",
    "        \"Yemekler fazlasıyla tuzlu geldi, hiç beğenmedim.\",\n",
    "        \"Kahvaltı muhteşemdi, her şeyi denemek istedim.\",\n",
    "        \"Fiyatlar oldukça makuldü, çok memnun kaldım.\",\n",
    "        \"Garsonlar çok yardımseverdi, teşekkürler.\",\n",
    "        \"Yemekler güzel ama servis biraz yavaştı.\",\n",
    "        \"Çocuklar için harika bir yer, çok eğlendiler.\",\n",
    "        \"Bir daha asla gitmeyeceğim, kötü bir deneyim yaşadım.\",\n",
    "        \"Mekanın atmosferi çok keyifliydi.\",\n",
    "        \"Yemeklerin tadı harikaydı, özellikle deniz ürünleri.\",\n",
    "        \"Şarap menüsü oldukça zengindi, beğendim.\",\n",
    "        \"Yemekler sıcak servis edilmedi, hayal kırıklığıydı.\",\n",
    "        \"Burgerleri gerçekten çok lezzetliydi.\",\n",
    "        \"Tatlıların fiyatı biraz yüksekti ama lezzetliydi.\",\n",
    "        \"Hizmet çok yavaştı ama yemekler fena değildi.\",\n",
    "        \"Gerçekten güzel bir akşam yemeği deneyimi yaşadık.\",\n",
    "        \"Sushi taze ve lezzetliydi, kesinlikle tavsiye ederim.\",\n",
    "        \"Garsonlar çok nazik ve yardımseverdi.\",\n",
    "        \"Hizmetin daha iyi olmasını beklerdim.\",\n",
    "        \"Kahvaltı menüsü oldukça zengindi, çok beğendim.\",\n",
    "        \"Yemekler çok lezzetliydi ama servis biraz yavaştı.\",\n",
    "        \"Fiyatlar oldukça makuldü, bu kadar iyi hizmete.\",\n",
    "        \"Mekan çok temizdi, bu benim için önemli.\",\n",
    "        \"Tatlıların çok şekerli olduğunu düşündüm.\",\n",
    "        \"Hizmet yavaş ama mekan güzeldi.\",\n",
    "        \"Yemeklerin lezzeti harikaydı ama porsiyonlar küçük.\",\n",
    "        \"Kendimi çok özel hissettim, teşekkürler.\",\n",
    "        \"Güzel bir akşam yemeği, tekrar geleceğim.\",\n",
    "        \"Çalışanlar çok güler yüzlüydü.\",\n",
    "        \"Pasta çok güzeldi, özellikle çikolatalı.\",\n",
    "        \"Biraz beklemek zorunda kaldık ama değdi.\",\n",
    "        \"Sadece fiyatlar biraz yüksekti ama lezzet buna değer.\",\n",
    "        \"Mekan oldukça kalabalıktı ama hizmet güzel.\",\n",
    "        \"Garsonlar çok nazik ama biraz daha hızlı olabilirdi.\",\n",
    "        \"Yemeklerin sunumu gerçekten etkileyiciydi.\",\n",
    "        \"Yemekler çok lezzetliydi ama garsonlar nazik değildi.\",\n",
    "        \"Çok güzel bir akşam yemeği deneyimi yaşadım.\",\n",
    "        \"Pasta siparişi verdim ama çok uzun sürdü.\"\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
    "        \"positive\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
    "        \"positive\", \"positive\", \"positive\", \"negative\", \"negative\",\n",
    "        \"positive\", \"positive\", \"positive\", \"negative\", \"positive\",\n",
    "        \"negative\", \"positive\", \"positive\", \"positive\", \"positive\",\n",
    "        \"negative\", \"positive\", \"positive\", \"negative\", \"negative\",\n",
    "        \"negative\", \"positive\", \"positive\", \"positive\", \"positive\",\n",
    "        \"positive\", \"positive\", \"positive\", \"positive\", \"negative\",\n",
    "        \"negative\", \"positive\", \"positive\", \"positive\", \"negative\"\n",
    "\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cde31bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "23661aa0-bb53-40da-acf7-a541e92c3386",
       "rows": [
        [
         "0",
         "Yemekler harikaydı, her şey taze ve lezzetliydi.",
         "positive"
        ],
        [
         "1",
         "Garson çok ilgisizdi, siparişimi unuttular.",
         "negative"
        ],
        [
         "2",
         "Tatlılar gerçekten çok güzeldi, bayıldım!",
         "positive"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yemekler harikaydı, her şey taze ve lezzetliydi.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Garson çok ilgisizdi, siparişimi unuttular.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tatlılar gerçekten çok güzeldi, bayıldım!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text     label\n",
       "0  Yemekler harikaydı, her şey taze ve lezzetliydi.  positive\n",
       "1       Garson çok ilgisizdi, siparişimi unuttular.  negative\n",
       "2         Tatlılar gerçekten çok güzeldi, bayıldım!  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581c392",
   "metadata": {},
   "source": [
    "#### 7.4 RNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7cfd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 8)\n"
     ]
    }
   ],
   "source": [
    "# metin temizleme ve preprocessing: tokenization, padding, label encoding, train test split\n",
    "\n",
    "# tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# padding process \n",
    "maxlen = max(len(seq) for seq in sequences)\n",
    "X = pad_sequences(sequences, maxlen = maxlen)\n",
    "print(X.shape)\n",
    "\n",
    "# label encoding \n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3910bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metin temsili: word embedding: word2vec\n",
    "\n",
    "sentences = [text.split() for text in df[\"text\"]]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=50, window = 5, min_count=1) \n",
    "\n",
    "embedding_dim = 50\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe205ef",
   "metadata": {},
   "source": [
    "#### 7.5 RNN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd24b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "20/20 [==============================] - 2s 18ms/step - loss: 0.6717 - accuracy: 0.6500 - val_loss: 0.7201 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.7000 - val_loss: 0.7957 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7000 - val_loss: 0.7425 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7000 - val_loss: 0.7602 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7000 - val_loss: 0.7901 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7000 - val_loss: 0.8081 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7000 - val_loss: 0.7644 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7250 - val_loss: 0.8716 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7250 - val_loss: 0.8965 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7500 - val_loss: 0.9018 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9018 - accuracy: 0.4000\n",
      "Test loss: 0.9017836451530457\n",
      "Test Accuracy: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "# modelling: build, train ve test rnn modeli \n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "# embedding\n",
    "model.add(Embedding(input_dim = len(word_index) + 1, output_dim = embedding_dim, weights = [embedding_matrix], input_length=maxlen, trainable = False))\n",
    "\n",
    "# RNN layer\n",
    "model.add(SimpleRNN(50, return_sequences = False))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size = 2, validation_data=(X_test, y_test))\n",
    "\n",
    "# evaluate rnn model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18bd5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 278ms/step\n",
      "Result: positive\n"
     ]
    }
   ],
   "source": [
    "# cumle siniflandirma calismasi\n",
    "def classify_sentence(sentence):\n",
    "    \n",
    "    seq = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_seq = pad_sequences(seq, maxlen = maxlen) \n",
    "    \n",
    "    prediction = model.predict(padded_seq)\n",
    "    \n",
    "    predicted_class = (prediction > 0.5).astype(int)\n",
    "    label = \"positive\" if predicted_class[0][0] == 1 else \"negative\"\n",
    "    \n",
    "    return label\n",
    "\n",
    "sentence = \"Restaurant çok temizdi ve yemekler çok güzeldi\"\n",
    "\n",
    "result = classify_sentence(sentence)\n",
    "print(f\"Result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
