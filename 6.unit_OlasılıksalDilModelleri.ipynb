{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a2af0f",
   "metadata": {},
   "source": [
    "### 6.2 N-Gramlar Modelleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925274ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avantajlar \n",
    "# - Basit ve hızlı \n",
    "# - Yerel bağıntıları iyi yakalar \n",
    "# Dezavantajlar \n",
    "# - Bağlam sınırlaması\n",
    "# - Veri Gereksinimi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412548c",
   "metadata": {},
   "source": [
    "### 6.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd9cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# ornek veri seti olustur\n",
    "corpus = [ \n",
    "    \"I love apple\",\n",
    "    \"I love him\",\n",
    "    \"I love NLP\",\n",
    "    \"You love me\",\n",
    "    \"He loves apple\",\n",
    "    \"I love you and love me\"\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Problem tanimi yapalim: \n",
    "   dil modeli yapmak istiyoruz \n",
    "   amac 1 kelimeden sonra gelecek kelimeyi tahmin etmek: metin turetmek/olusturmak\n",
    "   bunun icin n gram dil modelini kullanıcaz \n",
    "\n",
    "   ex: I ...(love) ...(apple)\n",
    "\"\"\"\n",
    "# veriler token haline getir\n",
    "tokens = [word_tokenize(sentence.lower()) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5875cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram 2 li kelime grupları olustur\n",
    "bigrams = []\n",
    "for token_list in tokens :\n",
    "    bigrams.extend(list(ngrams(token_list, 2)))\n",
    "bigrams_freq = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6af9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram 3 li kelime grupları olustur\n",
    "trigrams = []\n",
    "for token_list in tokens :\n",
    "    trigrams.extend(list(ngrams(token_list, 3)))\n",
    "trigrams_freq = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf99365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you kelimesini olma olasılıgı : 0.25\n",
      "apple kelimesini olma olasılıgı : 0.25\n"
     ]
    }
   ],
   "source": [
    "# model testing\n",
    "\n",
    "# \"i love\" bigram2indan sonra \"you\" veya \"apple\" kelimelerinin gelme olasılıklarını hesaplayalım\n",
    "bigram =(\"i\",\"love\") # hedef bigram \n",
    "# \" i love you \" olma olasılıgı\n",
    "prob_you = trigrams_freq[(\"i\",\"love\",\"you\")] / bigrams_freq[bigram]\n",
    "print(f\"you kelimesini olma olasılıgı : {prob_you}\")\n",
    "\n",
    "# i love apple olma olaslıgı\n",
    "prob_apple= trigrams_freq[(\"i\",\"love\",\"apple\")] / bigrams_freq[bigram]\n",
    "print(f\"apple kelimesini olma olasılıgı : {prob_apple}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426906a",
   "metadata": {},
   "source": [
    "### 6.4 Hidden Markov Models ( HMM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f0ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullamım:\n",
    "#     - Konusma tanıma \n",
    "#     - Dil modelleme\n",
    "#     - Parça etiketleme ( Part pf Speech Tagging )\n",
    "# Avantajlar:\n",
    "#     - Bağlam Modelleme\n",
    "#     - Vrimli Algoritmalar\n",
    "# Dezavantajlar:\n",
    "#     - Basitestirici Varsayımlar\n",
    "#     - Egitim zorlugu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ab54e",
   "metadata": {},
   "source": [
    "### 6.5 HMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eebfa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeni cumle 1: [('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('student', 'NN')]\n",
      "yeni cumle 2: [('He', 'PRP'), ('is', 'PRP'), ('a', 'PRP'), ('driver', 'PRP')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\hmm.py:333: RuntimeWarning: overflow encountered in cast\n",
      "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\hmm.py:335: RuntimeWarning: overflow encountered in cast\n",
      "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\hmm.py:331: RuntimeWarning: overflow encountered in cast\n",
      "  P[i] = self._priors.logprob(si)\n",
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tag\\hmm.py:363: RuntimeWarning: overflow encountered in cast\n",
      "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "\n",
    "# ornek traning daa tanimla \n",
    "train_data = [\n",
    "    [(\"I\", \"PRP\"), (\"am\", \"VBP\"), (\"a\", \"DT\"), (\"teacher\", \"NN\")],\n",
    "    [(\"You\", \"PRP\"), (\"are\", \"VBP\"), (\"a\", \"DT\"), (\"student\", \"NN\")]\n",
    "]\n",
    "\n",
    "# train HMM\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = trainer.train(train_data)\n",
    "\n",
    "# yeni bir cumle olustur ve cumlenin icersinde bulunan her bir sozcugun turunu etiketle\n",
    "\n",
    "test_sentence = \"I am a student\".split() # cumelyi liste haline getir\n",
    "tags = hmm_tagger.tag(test_sentence)\n",
    "print(f\"yeni cumle 1: {tags}\")\n",
    "\n",
    "test_sentence = \"He is a driver\".split() # cumelyi liste haline getir\n",
    "tags = hmm_tagger.tag(test_sentence)\n",
    "print(f\"yeni cumle 2: {tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6fe97",
   "metadata": {},
   "source": [
    "### 6.6 HMM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e8fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cnts.ua.ac.be/conll2000/chunking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: [[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "# gerekli veri setini iceriye aktar \n",
    "nltk.download(\"conll2000\", quiet=True) # quiet=True indirme esnasında ekranda bilgi vermesin\n",
    "\n",
    "train_data = conll2000.tagged_sents(\"train.txt\")\n",
    "test_data = conll2000.tagged_sents(\"test.txt\")\n",
    "\n",
    "print(f\"train_data: {train_data[:1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be596afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeni cumle: [('I', 'PRP'), ('like', 'IN'), ('going', 'VBG'), ('to', 'TO'), ('school', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# train hmm \n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = trainer.train(train_data)\n",
    "\n",
    "# yeni cumle ve test \n",
    "test_sentence = \" I like going to school\".split()\n",
    "tags = hmm_tagger.tag(test_sentence)\n",
    "print(f\"yeni cumle: {tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a413c",
   "metadata": {},
   "source": [
    "### 6.7 Maximum Entropy Models ( MaxEnt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499faf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullanım: \n",
    "#     -MaxEnt modelelri ozellkle sınıflandırma görevleirinde kullanılır \n",
    "#     -Örn, bir cumle belirli bir sınıfa ( poz , neg duygu gibi) ait olma olasılıgını tahmin edebilir \n",
    "# Avantajlar: \n",
    "#     -Esneklik\n",
    "#     -İyi Genelleme\n",
    "# Dezavantajlar:\n",
    "#     -Hesaplama Maliyetleri\n",
    "#     -Özellik Mühendisliği"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9be55a",
   "metadata": {},
   "source": [
    "### 6.8 MaxEnt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0c4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (10 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.500\n",
      "             2          -0.40641        1.000\n",
      "             3          -0.28861        1.000\n",
      "             4          -0.22397        1.000\n",
      "             5          -0.18304        1.000\n",
      "             6          -0.15479        1.000\n",
      "             7          -0.13410        1.000\n",
      "             8          -0.11829        1.000\n",
      "             9          -0.10582        1.000\n",
      "         Final          -0.09573        1.000\n",
      "Result: positive\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "# veri seti tanımşama \n",
    "train_data = [ \n",
    "    ({\"love\": True, \"amazing\": True, \"happy\":True, \"terrible\":False}, \"positive\" ),\n",
    "    ({\"hate\": True, \"terrible\": True}, \"negative\"),\n",
    "    ({\"joy\": True, \"happy\": True, \"hate\": False}, \"positive\"),\n",
    "    ({\"sad\": True, \"depressed\": True, \"love\": False}, \"negative\")\n",
    "]\n",
    "\n",
    "#train maximum entropy classifier\n",
    "classifier = MaxentClassifier.train(train_data, max_iter = 10)\n",
    "\n",
    "# yeni cumle ile test\n",
    "test_sentence = \"I love this movie and it was amazing\"\n",
    "features = {word:(word in test_sentence.lower().split()) for word in [ \"love\", \"amazing\", \"happy\", \"terrible\", \"hate\", \"joy\", \"sad\", \"depressed\"]}\n",
    "label = classifier.classify(features)\n",
    "print(f\"Result: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
