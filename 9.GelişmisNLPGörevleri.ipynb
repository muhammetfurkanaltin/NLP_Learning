{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28c8f8d",
   "metadata": {},
   "source": [
    "### 9.3 BERT ile Soru Cevaplama (Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a2109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: paris\n",
      "Answer: the scientific study of algorithms and statistical models\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy==1.24.4 --force-reinstall\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "def predict_answer(context, question):\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        question, context,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "    attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_scores, end_scores = model(input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "\n",
    "    start_index = torch.argmax(start_scores, dim=1).item()\n",
    "    end_index = torch.argmax(end_scores, dim=1).item()\n",
    "\n",
    "    answer_tokens = tokenizer.convert_ids_to_tokens(input_ids[0][start_index: end_index + 1])\n",
    "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Test 1\n",
    "question = \"What is the capital of France\"\n",
    "context = \"France, officially the French Republic, is a country whose capital is Paris\"\n",
    "answer = predict_answer(context, question)\n",
    "print(f\"Answer: {answer}\")\n",
    "\n",
    "# Test 2\n",
    "question = \"What is Machine Learning?\"\n",
    "context = \"\"\" Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance \n",
    "on a specific task. Machine learning algorithms build a mathematical model of sample data, known as 'training data', in order to make predictions or \n",
    "decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection \n",
    "of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning \n",
    "is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, \n",
    "theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
    "data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as predictive analytics. \"\"\"\n",
    "answer = predict_answer(context, question)\n",
    "print(f\"Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acdf49",
   "metadata": {},
   "source": [
    "#### 9.4 GPT ile Soru Cevaplama (Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6620175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The capital of France is Paris.\n",
      "\n",
      "Question: What is the capital of France, Context: France, officially the French Republic,\n",
      "Answer: Question: What is Machine Learning?, Context:  Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance \n",
      "                on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or \n",
      "                decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection \n",
      "                of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning \n",
      "                is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, \n",
      "                theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
      "                data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics. . Please answer the question according to context.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_answer(context, question):\n",
    "    \n",
    "    input_text = f\"Question: {question}, Context: {context}. Please answer the question according to context\"\n",
    "    \n",
    "    # tokenize\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # modeli calistir\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs, max_length = 300)\n",
    "        \n",
    "    # uretilen yaniti decode edelim\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True) # merhaba<EOS><PAD>\n",
    "    \n",
    "    # tanitlari ayiklayalim\n",
    "    answer = answer.split(\"Answer:\")[-1].strip()\n",
    "    \n",
    "    return answer\n",
    "\n",
    "question = \"What is the capital of France\"\n",
    "context = \"France, officially the French Republic, is a country whose capital is Paris\"\n",
    "\n",
    "answer = generate_answer(context, question)\n",
    "print(f\"Answer: {answer}\")\n",
    "\n",
    "question = '''What is Machine Learning?'''\n",
    "context = ''' Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance \n",
    "                on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or \n",
    "                decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection \n",
    "                of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning \n",
    "                is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, \n",
    "                theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
    "                data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics. '''\n",
    "\n",
    "answer = generate_answer(context, question)\n",
    "print(f\"Answer: {answer}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d3102",
   "metadata": {},
   "source": [
    "### 9.5 Bilgi Getirimi ( Information Retrieval )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72d568",
   "metadata": {},
   "source": [
    "![ScreenS/9.5_info.PNG](ScreenS/9.5_info.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a65195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Document: Machine learning is a field of artificial intelligence \n",
      "0.634821891784668\n",
      "Document: Natural language processing involves understanding human language \n",
      "0.626939058303833\n",
      "Document: Artificial intelligence encomppases machine learning and natural language processing (nlp) \n",
      "0.5046247243881226\n",
      "Document: Deep learning is a subset of machine learning \n",
      "0.6263622641563416\n",
      "Document: Data science combines statistics, adta analysis and machine learning \n",
      "0.6136887073516846\n",
      "Document: I go to shop \n",
      "0.5354946255683899\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# tokenizer and model create \n",
    "model_name = \"bert-base-uncased\" # kucuk boyutlu bert modeli \n",
    "tokenizer = BertTokenizer.from_pretrained(model_name) # tokenizer yukle\n",
    "model = BertModel.from_pretrained(model_name) # onceden egitilmis bert modeli \n",
    "\n",
    "# veri olustur: karsılastırılcak belgeleri ve sorgu cumlemizi olustur \n",
    "documents = [\n",
    "    \"Machine learning is a field of artificial intelligence\",\n",
    "    \"Natural language processing involves understanding human language\",\n",
    "    \"Artificial intelligence encomppases machine learning and natural language processing (nlp)\",\n",
    "    \"Deep learning is a subset of machine learning\",\n",
    "    \"Data science combines statistics, adta analysis and machine learning\",\n",
    "    \"I go to shop\"\n",
    "]\n",
    "\n",
    "query = \"What is deep learning?\"\n",
    "\n",
    "# bert ile bilgi getirimi\n",
    "\n",
    "def get_embedding(text):\n",
    "    # tokenization\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # modeli calistir\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # son gizli katmani alalim\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    \n",
    "    # metni temsili olustur\n",
    "    embedding = last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    # vektoru numpy olarak return et\n",
    "    return embedding.detach().numpy()\n",
    "\n",
    "# belgeler ve sorgu icin embedding vektorlerini al\n",
    "doc_embeddings = np.vstack([get_embedding(doc) for doc in documents])\n",
    "query_embedding = get_embedding(query)\n",
    "\n",
    "# kosinus benzerligi ile belgeler arasinda benzerligi hesaplayalim\n",
    "similarities = cosine_similarity(query_embedding, doc_embeddings)\n",
    "\n",
    "# her belgenin benzerlik skoru\n",
    "for i, score in enumerate(similarities[0]):\n",
    "    print(f\"Document: {documents[i]} \\n{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9125082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document: Machine learning is a field of artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "most_similar_index = similarities.argmax()\n",
    "\n",
    "print(f\"Most similar document: {documents[most_similar_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966403b9",
   "metadata": {},
   "source": [
    "### 9.7 Derin Ogrenme ile Öneri sistemleri ( Recommendation system )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911208a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.2845 - val_loss: 24.9078\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.2183 - val_loss: 24.8087\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.1513 - val_loss: 24.7098\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.0809 - val_loss: 24.6108\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.0059 - val_loss: 24.5119\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9255 - val_loss: 24.4129\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.8392 - val_loss: 24.3142\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.7466 - val_loss: 24.2157\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.6472 - val_loss: 24.1176\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.5406 - val_loss: 24.0200\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.4264 - val_loss: 23.9229\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3042 - val_loss: 23.8263\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.1735 - val_loss: 23.7301\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.0341 - val_loss: 23.6345\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8855 - val_loss: 23.5393\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7275 - val_loss: 23.4447\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5598 - val_loss: 23.3506\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.3823 - val_loss: 23.2571\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1948 - val_loss: 23.1642\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9973 - val_loss: 23.0719\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7898 - val_loss: 22.9804\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5725 - val_loss: 22.8897\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3455 - val_loss: 22.7997\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.1093 - val_loss: 22.7107\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8643 - val_loss: 22.6226\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6112 - val_loss: 22.5356\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.3508 - val_loss: 22.4497\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0840 - val_loss: 22.3649\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8117 - val_loss: 22.2815\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5353 - val_loss: 22.1996\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2557 - val_loss: 22.1191\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.9743 - val_loss: 22.0402\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6921 - val_loss: 21.9631\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4101 - val_loss: 21.8878\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1294 - val_loss: 21.8145\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8513 - val_loss: 21.7433\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5772 - val_loss: 21.6743\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3092 - val_loss: 21.6075\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0496 - val_loss: 21.5432\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8008 - val_loss: 21.4813\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5656 - val_loss: 21.4221\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3462 - val_loss: 21.3655\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1449 - val_loss: 21.3118\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9631 - val_loss: 21.2609\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8020 - val_loss: 21.2129\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6620 - val_loss: 21.1680\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5429 - val_loss: 21.1261\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4437 - val_loss: 21.0873\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3631 - val_loss: 21.0516\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2994 - val_loss: 21.0190\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2506 - val_loss: 20.9894\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2142 - val_loss: 20.9629\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1882 - val_loss: 20.9394\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1703 - val_loss: 20.9187\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1585 - val_loss: 20.9008\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1508 - val_loss: 20.8855\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1458 - val_loss: 20.8727\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1419 - val_loss: 20.8622\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1382 - val_loss: 20.8537\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1339 - val_loss: 20.8472\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1285 - val_loss: 20.8424\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1217 - val_loss: 20.8391\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1138 - val_loss: 20.8371\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1048 - val_loss: 20.8361\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0951 - val_loss: 20.8359\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0851 - val_loss: 20.8365\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0752 - val_loss: 20.8375\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0658 - val_loss: 20.8388\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0571 - val_loss: 20.8402\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0494 - val_loss: 20.8417\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0427 - val_loss: 20.8431\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0371 - val_loss: 20.8442\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0325 - val_loss: 20.8451\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0287 - val_loss: 20.8457\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0257 - val_loss: 20.8459\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0233 - val_loss: 20.8457\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0213 - val_loss: 20.8451\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0195 - val_loss: 20.8441\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0179 - val_loss: 20.8427\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0164 - val_loss: 20.8409\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0149 - val_loss: 20.8388\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0135 - val_loss: 20.8365\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0121 - val_loss: 20.8339\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0107 - val_loss: 20.8312\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0095 - val_loss: 20.8283\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 20.8254\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0074 - val_loss: 20.8225\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - val_loss: 20.8196\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 20.8168\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 20.8142\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 20.8117\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 20.8095\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 20.8074\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 20.8056\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 20.8041\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - val_loss: 20.8028\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 20.8018\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 20.8011\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 20.8005\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 20.8002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2254\n",
      "test: 7.225420951843262\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Predicted rating for user: 0, item: 0, 5.03\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Problem tanimi: Oneri sistemi\n",
    "    user (kullanici) - item (urunler) - rating (puanlar)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input,Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# veri setini olustur\n",
    "user_ids = np.array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
    "item_ids = np.array([0, 1, 2, 3, 4, 1, 2, 3, 4, 5])\n",
    "ratings  = np.array([5, 4, 3, 2, 1, 4, 5, 3, 2, 1])\n",
    "\n",
    "# train test split\n",
    "user_ids_train, user_ids_test, item_ids_train, item_ids_test, ratings_train, ratings_test = train_test_split(user_ids, item_ids, \n",
    "                                                                                                             ratings, test_size = 0.2, \n",
    "                                                                                                             random_state = 42)\n",
    "\n",
    "# creaate neural network \n",
    "def create_model(num_users, num_items, embedding_dim):\n",
    "\n",
    "    # input katmani\n",
    "    user_input = Input(shape=(1,), name = \"user\")\n",
    "    item_input = Input(shape=(1,), name = \"item\")\n",
    "\n",
    "    # embedding katmani \n",
    "    user_embedding = Embedding(input_dim = num_users, output_dim = embedding_dim, name = \"user_embedding\")(user_input)\n",
    "    item_embedding = Embedding(input_dim = num_items, output_dim = embedding_dim, name = \"item_embedding\")(item_input)\n",
    "\n",
    "    # vektorleri duzlestir \n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "    dot_product = Dot(axes = 1)([user_vecs, item_vecs])\n",
    "    output = Dense(1)(dot_product)\n",
    "\n",
    "    model = Model(inputs = [user_input, item_input], outputs = output)\n",
    "    model.compile(optimizer=Adam(learning_rate = 0.01), loss = \"mean_squared_error\")\n",
    "    return model\n",
    "# train and test \n",
    "\n",
    "num_users = 5\n",
    "num_items = 6\n",
    "embedding_dim = 8\n",
    "model = create_model(num_users, num_items, embedding_dim)\n",
    "model.fit([user_ids_train, item_ids_train], ratings_train, epochs = 100, verbose = 1, validation_split = 0.1)\n",
    "\n",
    "loss = model.evaluate([user_ids_test, item_ids_test], ratings_test)\n",
    "print(f\"test: {loss}\")\n",
    "\n",
    "# recommendation test\n",
    "user_id = np.array([0])\n",
    "item_id = np.array([0])\n",
    "prediction = model.predict([user_id, item_id])\n",
    "\n",
    "print(f\"Predicted rating for user: {user_id[0]}, item: {item_id[0]}, {prediction[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793ebac",
   "metadata": {},
   "source": [
    "### 9.9 Makine ogrenmesi ile Oneri sistemi ( Recommendation system )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from surprise import Dataset, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# import veri seti\n",
    "data = Dataset.load_builtin(\"ml-100k\") # (kullanici id, film id, puan)\n",
    "\n",
    "# train test split\n",
    "trainset, testset = train_test_split(data, test_size = 0.2) \n",
    "\n",
    "# ML model create: KNN\n",
    "model_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\":True # kullanicilar arasi benzerlik\n",
    "    }\n",
    "\n",
    "# train\n",
    "model = KNNBasic(sim_options=model_options)\n",
    "model.fit(trainset)\n",
    "\n",
    "# test\n",
    "prediction = model.test(testset)\n",
    "accuracy.rmse(prediction)\n",
    "\n",
    "# recommendation system \n",
    "def get_top_n(predictions, n = 10):\n",
    "    \n",
    "    top_n = {}\n",
    "    \n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if not top_n.get(uid):\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "        \n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "n = 5\n",
    "top_n = get_top_n(prediction, n)\n",
    "\n",
    "user_id = \"2\"\n",
    "print(f\"top {n} recommendation for user {user_id}\")\n",
    "for item_id, rating in top_n[user_id]:\n",
    "    print(f\"item id: {item_id}, score: {rating}\")\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "RMSE: 0.98  # (bu sayı değişebilir, modelin tahmin doğruluğu)\n",
    "\n",
    "top 5 recommendation for user 2\n",
    "item id: 169, score: 5.0\n",
    "item id: 174, score: 5.0\n",
    "item id: 98, score: 5.0\n",
    "item id: 96, score: 4.99\n",
    "item id: 318, score: 4.99\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97d917",
   "metadata": {},
   "source": [
    "### Makine Çevirisi ( Machine Translation )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e45f9",
   "metadata": {},
   "source": [
    "![ScreenS/9.10_mt.PNG](ScreenS/9.10_mt.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mfurk\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-fr. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated_text: Bonjour, quel est votre nom\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\" # eng to fr --- \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"Hello, what is your name\"\n",
    "\n",
    "# encode edelim, sonrasinda modele input olarak verelim\n",
    "translated_text = model.generate(**tokenizer(text, return_tensors=\"pt\", padding = True))\n",
    "\n",
    "# translated text metne donusturulur\n",
    "translated_text = tokenizer.decode(translated_text[0], skip_special_tokens=True)\n",
    "print(f\"Translated_text: {translated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f357bff",
   "metadata": {},
   "source": [
    "### 9.12 Metin Özetleme ( Text Summarization )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df61b4e",
   "metadata": {},
   "source": [
    "![ScreenS/9.12_TS.PNG](ScreenS/9.12_TS.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e239b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\mfurk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mfurk\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "# ozetleme pipeline yukle\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "text = \"\"\"\n",
    "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use \n",
    "to progressively improve their performance on a specific task. Machine learning algorithms build a mathematical \n",
    "model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly \n",
    "programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, \n",
    "detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific \n",
    "instructions for performing the task. Machine learning is closely related to computational statistics, which focuses \n",
    "on making predictions using computers. The study of mathematical optimization delivers methods, theory and application \n",
    "domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
    "data analysis through unsupervised learning. In its application across business problems, machine learning is also referred \n",
    "to as predictive analytics.\n",
    "\"\"\"\n",
    "\n",
    "# metni ozetleme\n",
    "summary = summarizer(\n",
    "    text, \n",
    "    max_length = 20,\n",
    "    min_length = 5,\n",
    "    do_sample = True\n",
    "    )\n",
    "\n",
    "print(summary[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11e2ac",
   "metadata": {},
   "source": [
    "### 9.14 ChatBotGeliştirme ve API Kullanımı "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"api-key\"\n",
    "\n",
    "def chat_with_gpt(prompt, history_list):\n",
    "    \n",
    "    responce = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [{\"role\":\"user\", \"content\": f\"Bu bizim mesajımız: {prompt}. Konuşma geçmişi: {history_list}\"}]\n",
    "        )\n",
    "    \n",
    "    return responce.choices[0].message.content.strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    history_list = []\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        user_input = input(\"Kullanıcı tarafından girilen mesaj:\" )\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"q\"]:\n",
    "            print(\"Konuşma tamamlandi\")\n",
    "            break\n",
    "        history_list.append(user_input)\n",
    "        responce = chat_with_gpt(user_input, history_list)\n",
    "        print(f\"Chatbot: {responce}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
