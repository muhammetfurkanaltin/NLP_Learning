{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08145eb8",
   "metadata": {},
   "source": [
    "### 5.3 Bag of Words (BoW) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b977117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bahcede' 'evde' 'kedi']\n",
      "[[1 0 1]\n",
      " [0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# count vectorizer iceriye aktar\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# veri seti olustur\n",
    "documents = [\n",
    "    \"kedi bahcede\",\n",
    "    \"kedi evde\"]\n",
    "\n",
    "# vectorizer tanimla \n",
    "vecto = CountVectorizer()\n",
    "\n",
    "# metni sayisal vectorlere cevir \n",
    "X = vecto.fit_transform(documents)\n",
    "\n",
    "# kelime kumesi olsuturma [bahcede, evde, kedi]\n",
    "feature_names = vecto.get_feature_names_out()\n",
    "print(feature_names)\n",
    "\n",
    "# vector temsili \n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf7d88",
   "metadata": {},
   "source": [
    "### 5.4 BoW_imdb_datasets part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb7d9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re \n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "# metin temizleme \n",
    "documents = df[\"review\"]\n",
    "labels =df[\"sentiment\"] #posi or neg \n",
    "\n",
    "# metin temizleme \n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # buyuk kucuk harf cevrimi\n",
    "    text = text.lower()\n",
    "\n",
    "    # rakamlari temizle\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # kisa kelimeleri temizlenmesi\n",
    "    text = \" \".join([word for word in text.split() if len(word) > 2])\n",
    "\n",
    "    # stop kelimeleri temizle\n",
    "    stop_words = ['the', 'and', 'this', 'that', 'with','was','for', 'but', 'his']\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "\n",
    "    return text # temizlenms metin\n",
    "\n",
    "# metinleri temizle \n",
    "cleaned_doc = [clean_text(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8bf2e",
   "metadata": {},
   "source": [
    "### 5.5 part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb909504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[('movie', 123), ('film', 98), ('not', 96), ('its', 83), ('are', 80)]\n"
     ]
    }
   ],
   "source": [
    "# BoW \n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# metin -> sayisal hale getir \n",
    "X = vectorizer.fit_transform(cleaned_doc[:75])\n",
    "\n",
    "# vektor temsili goster \n",
    "print(X.toarray())\n",
    "\n",
    "df_bow = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# kelime frenkansini bul \n",
    "word_freq = X.sum(axis=0).A1\n",
    "word_freq = dict(zip(vectorizer.get_feature_names_out(), word_freq))\n",
    "\n",
    "# ilk 5 kelimeyi print et \n",
    "most_5 = Counter(word_freq).most_common(5)\n",
    "print(most_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef13c88",
   "metadata": {},
   "source": [
    "### 5.6 TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe7b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vektor temsil:\n",
      "[[0.83388421 0.         0.55193942]\n",
      " [0.         0.83388421 0.55193942]\n",
      " [0.60276058 0.         0.7979221 ]\n",
      " [0.         0.60276058 0.7979221 ]]\n",
      "tf_idf:\n",
      "bahcede    0.359161\n",
      "evde       0.359161\n",
      "kedi       0.674931\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ornek belge olustur\n",
    "documents = [\n",
    "    \"kedi bahcede\",\n",
    "    \"kedi evde\",\n",
    "    \"kedi bahcede kedi\",\n",
    "    \"kedi evde kedi\",\n",
    "]\n",
    "# vektorizer tanimla\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# meinleri sayisal hale cevir \n",
    "X = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# kelime kumesi incele\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# vektor temsilini incele\n",
    "print(f\"vektor temsil:\\n{X.toarray()}\")\n",
    "\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "# ortalama tf idf degerlerine bakalım \n",
    "tf_idf = df_tfidf.mean(axis=0)\n",
    "\n",
    "print(f\"tf_idf:\\n{tf_idf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6346d",
   "metadata": {},
   "source": [
    "### 5.8 Spam Datasets_Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d97cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mfurk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     words  tfidf_score\n",
      "1870  call     0.019546\n",
      "3631   get     0.013975\n",
      "4236   ill     0.012983\n",
      "2233  come     0.011805\n",
      "2829  dont     0.011044\n",
      "5003  ltgt     0.010865\n",
      "3710  good     0.010063\n",
      "4660  know     0.009999\n",
      "3734   got     0.009841\n",
      "4841  like     0.009737\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "df = pd.read_csv(\"sms_spam.csv\")\n",
    "\n",
    "# veri temizleeme \n",
    "text = df[\"text\"]\n",
    "def clean_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "        text = \" \".join([word for word in text.split() if len(word) > 2])\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "        return text # temizlenms metin\n",
    "# metinleri temizle\n",
    "cleaned_doc = [clean_text(doc) for doc in text]\n",
    "\n",
    "# tfidf \n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(cleaned_doc)\n",
    "\n",
    "# kelime kumesi incele\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_score = X.mean(axis=0).A1 # her kelimnin ortalama tf-idf degeri \n",
    "\n",
    "# tfidf skorlarını iceren bir df olsutur\n",
    "df_tfidf = pd.DataFrame({\"words\": feature_names, \"tfidf_score\": tfidf_score})\n",
    "\n",
    "# skorlarini sirala ve sonucları incele\n",
    "\n",
    "df_tfidf_sorted = df_tfidf.sort_values(by=\"tfidf_score\", ascending=False)\n",
    "print(df_tfidf_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52dec3",
   "metadata": {},
   "source": [
    "### 5.9 N-Gram Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15827bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"bu bir ornek metindir\"\n",
    "    # unigram (n=1) 'Bu' , 'bir' , 'ornek' , 'metindir'\n",
    "    # bigram (n=2) 'bu bir', 'bir ornek', 'ornek metindir'\n",
    "    # trigram (n=3) 'bu bir ornek', 'bir ornek metindir'\n",
    "\n",
    "    # ngram (n=4) 'bu bir ornek metindir'\n",
    "\n",
    "# hem modelleme yapılabilir \n",
    "# hemde sınıflandırma yapılabilir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56195365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Feature Names: \n",
      " ['bir' 'bu' 'metindir' 'ngram' 'ornek' 'çalısma' 'çalısmasıdır']\n",
      "Bigram Feature Names: \n",
      " ['bir ornek metindir' 'bu bir ornek' 'bu çalısma ngram'\n",
      " 'ngram çalısmasıdır bu' 'çalısma ngram çalısmasıdır'\n",
      " 'çalısmasıdır bu bir']\n",
      "Trigram Feature Names: \n",
      " ['bir ornek metindir' 'bu bir ornek' 'bu çalısma ngram'\n",
      " 'ngram çalısmasıdır bu' 'çalısma ngram çalısmasıdır'\n",
      " 'çalısmasıdır bu bir']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ornek metib \n",
    "documents = [\n",
    "    \"Bu çalısma NGram çalısmasıdır.\",\n",
    "    \"Bu çalısma NGram çalısmasıdır. Bu bir ornek metindir.\",\n",
    "]\n",
    "\n",
    "# unigram, bigram, trigram seklinde 3 farkli N degerine sahip ngram modeli \n",
    "vec_unigram = CountVectorizer(ngram_range=(1, 1))\n",
    "vec_bigram = CountVectorizer(ngram_range=(2,2))\n",
    "vec_trigram = CountVectorizer(ngram_range=(3,3))\n",
    "\n",
    "# unigram \n",
    "X_unigram = vec_unigram.fit_transform(documents)\n",
    "unigram_feature_names = vec_unigram.get_feature_names_out()\n",
    "\n",
    "# bigram \n",
    "X_bigram = vec_bigram.fit_transform(documents)\n",
    "bigram_features = vec_bigram.get_feature_names_out()\n",
    "\n",
    "# trigram \n",
    "X_trigram = vec_trigram.fit_transform(documents)\n",
    "bigram_features = vec_trigram.get_feature_names_out()\n",
    "\n",
    "# sonucların incelenmesi\n",
    "print(\"Unigram Feature Names: \\n\", unigram_feature_names )\n",
    "print(\"Bigram Feature Names: \\n\", bigram_features)\n",
    "print(\"Trigram Feature Names: \\n\", bigram_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
